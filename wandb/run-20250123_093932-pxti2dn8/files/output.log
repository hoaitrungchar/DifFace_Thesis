trainer:
  target: trainer.TrainerPredictedMask
model:
  target: models.SwinUnet.SwinUnet
  params:
    config: 1
    patch_size: 4
    num_classes: 1
    embed_dim: 96
    depths:
    - 2
    - 2
    - 2
    - 2
    depths_decoder:
    - 1
    - 2
    - 2
    - 2
    num_heads:
    - 3
    - 6
    - 12
    - 24
    window_size: 4
    qkv_bias: true
    in_chans: 3
    qk_scale: null
    drop_rate: 0.0
    drop_path_rate: 0.1
    ape: false
    patch_norm: true
    use_checkpoint: false
data:
  train:
    type: MaskTraining
    params:
      dataset_type: train
      dir_path:
      - /data/FFHQ/Dataset/FFHQ/train
      noise_path1:
      - /data/FFHQ/Dataset/CelebA-HQ/train
      noise_path2:
      - /data/FFHQ/Dataset/ImageNet/train
      transform_type: default
      transform_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
      transform_noise_type: crop_norm_train
      transform_noise_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
        img_resize: 256
        crop_size: 256
      need_path: false
      im_exts:
      - png
      - jpg
      - JPEG
      recursive: false
      kernel_gaussian_size: 3
      img_size: 256
      folder_mask_path:
      - /data/FFHQ/Dataset/Mask/train
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path:
          - /data/FFHQ/Dataset/Mask/train
  val:
    type: MaskTraining
    params:
      dataset_type: val
      dir_path:
      - /data/FFHQ/Dataset/FFHQ/val
      noise_path1:
      - /data/FFHQ/Dataset/CelebA-HQ/val
      noise_path2:
      - /data/FFHQ/Dataset/ImageNet/val
      transform_type: default
      transform_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
      transform_noise_type: crop_norm_val_test
      transform_noise_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
        img_resize: 256
        crop_size: 256
      need_path: false
      im_exts:
      - png
      - jpg
      - JPEG
      recursive: false
      kernel_gaussian_size: 3
      img_size: 256
      folder_mask_path:
      - /data/FFHQ/Dataset/Mask/val
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path:
          - /data/FFHQ/Dataset/Mask/val
train:
  lr: 0.001
  lr_min: 1.0e-06
  batch:
  - 16
  - 16
  microbatch: 16
  num_workers: 8
  prefetch_factor: 2
  iterations: 600000
  weight_decay: 0
  save_freq: 10
  val_freq: ${train.save_freq}
  log_freq:
  - 2
  - 2
  - 3
  ema_rate: 0.999
  loss_type: BCE
  tf_logging: true
  local_logging: true
project_name: Thesis_blind_image_inpainting
group_name: test
name: test
save_dir: /data/FFHQ/mask_log
resume: ''
cfg_path: /data/FFHQ/DifFace_Thesis/configs/training/predicted_mask_SwinUnet.yaml
seed: 10000

trainer:
  target: trainer.TrainerPredictedMask
model:
  target: models.SwinUnet.SwinUnet
  params:
    config: 1
    patch_size: 4
    num_classes: 1
    embed_dim: 96
    depths:
    - 2
    - 2
    - 2
    - 2
    depths_decoder:
    - 1
    - 2
    - 2
    - 2
    num_heads:
    - 3
    - 6
    - 12
    - 24
    window_size: 4
    qkv_bias: true
    in_chans: 3
    qk_scale: null
    drop_rate: 0.0
    drop_path_rate: 0.1
    ape: false
    patch_norm: true
    use_checkpoint: false
data:
  train:
    type: MaskTraining
    params:
      dataset_type: train
      dir_path:
      - /data/FFHQ/Dataset/FFHQ/train
      noise_path1:
      - /data/FFHQ/Dataset/CelebA-HQ/train
      noise_path2:
      - /data/FFHQ/Dataset/ImageNet/train
      transform_type: default
      transform_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
      transform_noise_type: crop_norm_train
      transform_noise_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
        img_resize: 256
        crop_size: 256
      need_path: false
      im_exts:
      - png
      - jpg
      - JPEG
      recursive: false
      kernel_gaussian_size: 3
      img_size: 256
      folder_mask_path:
      - /data/FFHQ/Dataset/Mask/train
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path:
          - /data/FFHQ/Dataset/Mask/train
  val:
    type: MaskTraining
    params:
      dataset_type: val
      dir_path:
      - /data/FFHQ/Dataset/FFHQ/val
      noise_path1:
      - /data/FFHQ/Dataset/CelebA-HQ/val
      noise_path2:
      - /data/FFHQ/Dataset/ImageNet/val
      transform_type: default
      transform_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
      transform_noise_type: crop_norm_val_test
      transform_noise_kwargs:
        mean:
        - 0.0
        - 0.0
        - 0.0
        std:
        - 1.0
        - 1.0
        - 1.0
        img_resize: 256
        crop_size: 256
      need_path: false
      im_exts:
      - png
      - jpg
      - JPEG
      recursive: false
      kernel_gaussian_size: 3
      img_size: 256
      folder_mask_path:
      - /data/FFHQ/Dataset/Mask/val
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path:
          - /data/FFHQ/Dataset/Mask/val
train:
  lr: 0.001
  lr_min: 1.0e-06
  batch:
  - 16
  - 16
  microbatch: 16
  num_workers: 8
  prefetch_factor: 2
  iterations: 600000
  weight_decay: 0
  save_freq: 10
  val_freq: ${train.save_freq}
  log_freq:
  - 2
  - 2
  - 3
  ema_rate: 0.999
  loss_type: BCE
  tf_logging: true
  local_logging: true
project_name: Thesis_blind_image_inpainting
group_name: test
name: test
save_dir: /data/FFHQ/mask_log
resume: ''
cfg_path: /data/FFHQ/DifFace_Thesis/configs/training/predicted_mask_SwinUnet.yaml
seed: 10000
/home/mmhk20/.local/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.1;num_classes:1
/usr/local/anaconda3/lib/python3.8/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
---final upsample expand_first---
Number of parameters: 27.15M
len_file_path_all 54999
24183
1281167
len_file_paths_noise 1305350
len_file_path_all 5000
2993
50000
len_file_paths_noise 52993
Number of images in train data set: 54999
Number of images in val data set: 5000
Train:000002/600000, Loss:6.88e-01, lr:1.00e-03, gradient:1.897706e+00
Train:000004/600000, Loss:6.38e-01, lr:1.00e-03, gradient:1.312109e+00
Train:000006/600000, Loss:5.78e-01, lr:1.00e-03, gradient:5.303388e-01
Train:000008/600000, Loss:5.77e-01, lr:1.00e-03, gradient:3.198338e-01
Train:000010/600000, Loss:5.43e-01, lr:1.00e-03, gradient:3.534693e-01
Elapsed time: 15.28s
============================================================
313 313
val:003/313, loss=0.73735787
val:006/313, loss=0.73624543
val:009/313, loss=0.73672058
val:012/313, loss=0.73661524
val:015/313, loss=0.73616389
val:018/313, loss=0.73742708
val:021/313, loss=0.73657276
val:024/313, loss=0.73786702
val:027/313, loss=0.73611257
val:030/313, loss=0.73686190
val:033/313, loss=0.73667125
val:036/313, loss=0.73684142
val:039/313, loss=0.73700293
val:042/313, loss=0.73641406
val:045/313, loss=0.73709480
val:048/313, loss=0.73699820
val:051/313, loss=0.73745879
val:054/313, loss=0.73641539
val:057/313, loss=0.73657580
val:060/313, loss=0.73651751
val:063/313, loss=0.73693128
val:066/313, loss=0.73718903
val:069/313, loss=0.73752656
val:072/313, loss=0.73587153
val:075/313, loss=0.73696164
val:078/313, loss=0.73739642
val:081/313, loss=0.73614444
val:084/313, loss=0.73659311
val:087/313, loss=0.73672225
val:090/313, loss=0.73788851
val:093/313, loss=0.73676701
val:096/313, loss=0.73670077
val:099/313, loss=0.73746530
val:102/313, loss=0.73535657
val:105/313, loss=0.73734746
val:108/313, loss=0.73720491
val:111/313, loss=0.73641111
val:114/313, loss=0.73616219
val:117/313, loss=0.73786139
val:120/313, loss=0.73677208
val:123/313, loss=0.73551333
val:126/313, loss=0.73666042
val:129/313, loss=0.73717088
val:132/313, loss=0.73675489
val:135/313, loss=0.73647855
val:138/313, loss=0.73677818
val:141/313, loss=0.73656078
val:144/313, loss=0.73636979
val:147/313, loss=0.73747096
val:150/313, loss=0.73644543
val:153/313, loss=0.73696782
val:156/313, loss=0.73657560
val:159/313, loss=0.73601456
val:162/313, loss=0.73689369
val:165/313, loss=0.73656841
val:168/313, loss=0.73638078
val:171/313, loss=0.73640351
val:174/313, loss=0.73729871
val:177/313, loss=0.73718196
val:180/313, loss=0.73706782
val:183/313, loss=0.73616743
val:186/313, loss=0.73520525
val:189/313, loss=0.73634738
val:192/313, loss=0.73790586
val:195/313, loss=0.73584580
val:198/313, loss=0.73643510
val:201/313, loss=0.73640349
val:204/313, loss=0.73642194
val:207/313, loss=0.73654495
val:210/313, loss=0.73675370
val:213/313, loss=0.73728551
val:216/313, loss=0.73719064
val:219/313, loss=0.73678476
val:222/313, loss=0.73676733
val:225/313, loss=0.73641686
val:228/313, loss=0.73709210
val:231/313, loss=0.73714042
val:234/313, loss=0.73671061
val:237/313, loss=0.73669970
val:240/313, loss=0.73699816
val:243/313, loss=0.73735942
val:246/313, loss=0.73727566
val:249/313, loss=0.73601246
val:252/313, loss=0.73656344
val:255/313, loss=0.73652798
val:258/313, loss=0.73637517
val:261/313, loss=0.73673896
val:264/313, loss=0.73719426
val:267/313, loss=0.73706830
val:270/313, loss=0.73731830
val:273/313, loss=0.73660719
val:276/313, loss=0.73708793
val:279/313, loss=0.73741559
val:282/313, loss=0.73658347
val:285/313, loss=0.73693530
val:288/313, loss=0.73681696
val:291/313, loss=0.73672881
val:294/313, loss=0.73679674
val:297/313, loss=0.73621778
val:300/313, loss=0.73673195
val:303/313, loss=0.73766230
val:306/313, loss=0.73583001
val:309/313, loss=0.73580796
val:312/313, loss=0.73683244
loss=0.73674931
Train:000012/600000, Loss:5.24e-01, lr:1.00e-03, gradient:3.479559e-01
Train:000014/600000, Loss:5.85e-01, lr:1.00e-03, gradient:4.737082e-01
Train:000016/600000, Loss:5.36e-01, lr:1.00e-03, gradient:6.973373e-01
Train:000018/600000, Loss:5.80e-01, lr:1.00e-03, gradient:4.215640e-01
Train:000020/600000, Loss:5.53e-01, lr:1.00e-03, gradient:3.028891e-01
Elapsed time: 10.93s
============================================================
313 313
val:003/313, loss=0.74344496
val:006/313, loss=0.74415004
val:009/313, loss=0.74524621
val:012/313, loss=0.74598897
val:015/313, loss=0.74410528
val:018/313, loss=0.74471980
val:021/313, loss=0.74564797
val:024/313, loss=0.74457028
val:027/313, loss=0.74428346
val:030/313, loss=0.74300069
val:033/313, loss=0.74434968
val:036/313, loss=0.74373863
val:039/313, loss=0.74448355
Traceback (most recent call last):
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py", line 500, in _save
    fh = fp.fileno()
AttributeError: '_idat' object has no attribute 'fileno'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 32, in <module>
    trainer.train()
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 323, in train
    self.validation()
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 1145, in validation
    self.logging_image(hq_pred.detach(), tag="pred", phase=phase, add_global_step=True)
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 372, in logging_image
    self.writer.add_image(
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py", line 656, in add_image
    image(tag, img_tensor, dataformats=dataformats), global_step, walltime
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py", line 575, in image
    image = make_image(tensor, rescale=rescale)
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py", line 631, in make_image
    image.save(output, format="PNG")
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/Image.py", line 2172, in save
    save_handler(self, fp, filename)
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/PngImagePlugin.py", line 1335, in _save
    ImageFile._save(im, _idat(fp, chunk), [("zip", (0, 0) + im.size, 0, rawmode)])
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py", line 514, in _save
    l, s, d = e.encode(bufsize)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py", line 500, in _save
    fh = fp.fileno()
AttributeError: '_idat' object has no attribute 'fileno'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 32, in <module>
    trainer.train()
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 323, in train
    self.validation()
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 1145, in validation
    self.logging_image(hq_pred.detach(), tag="pred", phase=phase, add_global_step=True)
  File "/data/FFHQ/DifFace_Thesis/trainer.py", line 372, in logging_image
    self.writer.add_image(
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py", line 656, in add_image
    image(tag, img_tensor, dataformats=dataformats), global_step, walltime
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py", line 575, in image
    image = make_image(tensor, rescale=rescale)
  File "/usr/local/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py", line 631, in make_image
    image.save(output, format="PNG")
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/Image.py", line 2172, in save
    save_handler(self, fp, filename)
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/PngImagePlugin.py", line 1335, in _save
    ImageFile._save(im, _idat(fp, chunk), [("zip", (0, 0) + im.size, 0, rawmode)])
  File "/usr/local/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py", line 514, in _save
    l, s, d = e.encode(bufsize)
KeyboardInterrupt
