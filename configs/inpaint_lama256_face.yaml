trainer:
  target: trainer.TrainerDifIRLPIPS

autoencoder:
  target: ldm.models.autoencoder.VQModelTorch
  ckpt_path: weights/celeba256_vq_f4_dim3_face.pth
  use_fp16: True
  tune_decoder: False
  
  params:
    lora_tune_decoder: False
    embed_dim: 3
    n_embed: 8192
    ddconfig:
      double_z: False
      z_channels: 3
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      padding_mode: zeros

model:
  target: models.unet.UNetModelSwin
  ckpt_path: ~
  params:
    image_size: 64
    in_channels: 3
    model_channels: 160
    out_channels: ${autoencoder.params.embed_dim}
    attention_resolutions: [64,32,16,8]
    dropout: 0
    channel_mult: [1, 2, 2, 4]
    num_res_blocks: [2, 2, 2, 2]
    conv_resample: True
    dims: 2
    use_fp16: False
    num_head_channels: 32
    use_scale_shift_norm: True
    resblock_updown: False
    swin_depth: 2
    swin_embed_dim: 192
    window_size: 8
    mlp_ratio: 4
    cond_lq: True
    cond_mask: True
    lq_size: 256
    
model_mask_target: models.swinunet.SwinUnet
model_mask_ckpt: /root/weights/FFHQ_mask_loss_000025565.pth
model_mask_params:
  config: 1
  patch_size: 4
  num_classes: 1        
  embed_dim: 96      
  depths: [2,2,2,2]        
  depths_decoder: [1, 2, 2, 2]
  num_heads: [3, 6, 12, 24]
  window_size: 4
  qkv_bias: True
  in_chans: 3
  qk_scale: null
  drop_rate: 0.
  drop_path_rate: 0.1
  ape: False
  patch_norm: True
  use_checkpoint: False

diffusion:
  target: models.script_util.create_gaussian_diffusion
  params:
    sf: 1
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 4
    min_noise_level: 0.2
    kappa: 2.0
    weighted_mse: False
    predict_type: xstart
    timestep_respacing: ~
    scale_factor: 1.0
    normalize_input: True
    latent_flag: True

data:
  train:
    type: blindinpainting
    params:
      dir_path: /root/data/FFHQ/train
      noise_path1: /root/data/CelebA-HQ/train
      noise_path2: [/root/data/ImageNet/train1,/root/data/ImageNet/train2,/root/data/ImageNet/train3,/root/data/ImageNet/train4,/root/data/ImageNet/train5,/root/data/ImageNet/train6,/root/data/ImageNet/train7,/root/data/ImageNet/train8,/root/data/ImageNet/train9,/root/data/ImageNet/train10,/root/data/ImageNet/train11,/root/data/ImageNet/train12,/root/data/ImageNet/train13]
      transform_type: default
      transform_kwargs:
        mean: 0.5
        std: 0.5
      need_path: False
      transform_noise_type: crop_norm_train
      transform_noise_kwargs:
        mean: 0.5
        std: 0.5
        img_resize: 256
        crop_size: 256
      transform_initial_mask: default
      transform_initial_kwargs:
        mean: 0
        std: 1
      im_exts: [png, jpg, JPEG]
      recursive: True
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path: /root/data/Mask/train
          recursive: True
      
  val:
    type: blindinpainting
    params:
      dir_path: /root/data/FFHQ/val
      noise_path1: /root/data/CelebA-HQ/val
      noise_path2: /root/data/ImageNet/val
      transform_type: default
      transform_kwargs:
          mean: 0.5
          std: 0.5
      transform_noise_type: crop_norm_val_test
      transform_noise_kwargs:
        mean: 0.5
        std: 0.5
        img_resize: 256
        crop_size: 256
      transform_initial_mask: default
      transform_initial_kwargs:
        mean: 0
        std: 1
      im_exts: [png, jpg, JPEG]
      recursive: True
      mask_kwargs:
        nvidia_mask_proba: 1
        nvidia_mask_kwargs:
          folder_mask_path: /root/data/Mask/val
          recursive: True
      

train:
  # learning rate
  lr: 5e-5                      # learning rate 
  lr_min: 2e-5
  lr_schedule: cosin
  warmup_iterations: 5000
  # dataloader
  batch: [24, 24]                
  microbatch: 24
  num_workers: 48
  prefetch_factor: 2            
  # optimization settings
  weight_decay: 0               
  ema_rate: 0.999
  iterations: 500000            # total iterations
  # save logging
  save_freq: 10000
  log_freq: [200, 2000, 1]         # [training loss, training images, val images]
  loss_coef: [1.0, 10.0]         # [mse, lpips]
  local_logging: True           # manually save images
  tf_logging: False             # tensorboard logging
  # validation settings
  use_ema_val: True            
  val_freq: ${train.save_freq}
  val_y_channel: False
  val_resolution: 256
  val_padding_mode: reflect
  # training setting
  use_amp: True               # amp training
  seed: 123456                  # random seed
  global_seeding: False
  # model compile
  compile:
    flag: False
    mode: reduce-overhead

project_name: Thesis_blind_image_inpainting
group_name: FFHQ_ResShift_mask
name: batch_24|constant_lr||lr_start_1e-4_end_1e-6||no_aug_mask||kernel_gaussian_size_3
wandb_id: l5jxzv8x